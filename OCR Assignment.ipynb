{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21a080a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gauri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3432 - loss: 2.4425\n",
      "Epoch 2/30\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7220 - loss: 0.9796\n",
      "Epoch 3/30\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7730 - loss: 0.7812\n",
      "Epoch 4/30\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7978 - loss: 0.6725\n",
      "Epoch 5/30\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8346 - loss: 0.5547\n",
      "Epoch 6/30\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8449 - loss: 0.5018\n",
      "Epoch 7/30\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8671 - loss: 0.4345\n",
      "Epoch 8/30\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8793 - loss: 0.3953\n",
      "Epoch 9/30\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8858 - loss: 0.3692\n",
      "Epoch 10/30\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8921 - loss: 0.3424\n",
      "Epoch 11/30\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8968 - loss: 0.3269\n",
      "Epoch 12/30\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9033 - loss: 0.3022\n",
      "Epoch 13/30\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9103 - loss: 0.2781\n",
      "Epoch 14/30\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9157 - loss: 0.2659\n",
      "Epoch 15/30\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9177 - loss: 0.2539\n",
      "Epoch 16/30\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9236 - loss: 0.2429\n",
      "Epoch 17/30\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9270 - loss: 0.2201\n",
      "Epoch 18/30\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9278 - loss: 0.2204\n",
      "Epoch 19/30\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9297 - loss: 0.2169\n",
      "Epoch 20/30\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9355 - loss: 0.2067\n",
      "Epoch 21/30\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9371 - loss: 0.1915\n",
      "Epoch 22/30\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9378 - loss: 0.1828\n",
      "Epoch 23/30\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9405 - loss: 0.1798\n",
      "Epoch 24/30\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9475 - loss: 0.1623\n",
      "Epoch 25/30\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9447 - loss: 0.1682\n",
      "Epoch 26/30\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9460 - loss: 0.1604\n",
      "Epoch 27/30\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9498 - loss: 0.1551\n",
      "Epoch 28/30\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9485 - loss: 0.1545\n",
      "Epoch 29/30\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9518 - loss: 0.1414\n",
      "Epoch 30/30\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9536 - loss: 0.1397\n",
      "Training time: 45.77 seconds\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "Prediction time: 0.13 seconds\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tkinter as tk\n",
    "from tkinter import Label, StringVar, Button, Entry\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Load the dataset\n",
    "data_path = 'letter-recognition.data'\n",
    "columns = ['letter'] + [f'feature_{i}' for i in range(16)]\n",
    "df = pd.read_csv(data_path, names=columns)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['target'] = label_encoder.fit_transform(df['letter'])\n",
    "X = df.drop(['letter', 'target'], axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Build the deep neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(16,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(26, activation='softmax'))  # 26 classes for letters\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "start_training_time = time.time()\n",
    "model.fit(X, y, epochs=30, batch_size=32)\n",
    "end_training_time = time.time()\n",
    "training_time = end_training_time - start_training_time\n",
    "print(f\"Training time: {training_time:.2f} seconds\")\n",
    "\n",
    "# Define the class mapping dictionary as a global variable\n",
    "class_mapping = {\n",
    "    0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'J',\n",
    "    10: 'K', 11: 'L', 12: 'M', 13: 'N', 14: 'O', 15: 'P', 16: 'Q', 17: 'R', 18: 'S', 19: 'T',\n",
    "    20: 'U', 21: 'V', 22: 'W', 23: 'X', 24: 'Y', 25: 'Z'\n",
    "}\n",
    "\n",
    "# Create a simple GUI\n",
    "def predict_letter():\n",
    "    start_prediction_time = time.time()\n",
    "    user_input = entry.get()\n",
    "    user_input_list = [int(x) for x in user_input.split(',')]\n",
    "    new_data = np.array(user_input_list).reshape(1, -1)\n",
    "\n",
    "    predictions = model.predict(new_data)\n",
    "    predicted_class = np.argmax(predictions)\n",
    "    predicted_letter = class_mapping[predicted_class]\n",
    "\n",
    "    result_var.set(f'The predicted class is: {predicted_class}, which corresponds to the letter: {predicted_letter}')\n",
    "    \n",
    "    end_prediction_time = time.time()\n",
    "    prediction_time = end_prediction_time - start_prediction_time\n",
    "    \n",
    "    result_var.set(result_var.get() + f'\\nPrediction time: {prediction_time:.2f} seconds\\nTraining time: {training_time:.2f} seconds')\n",
    "    print(f\"Prediction time: {prediction_time:.2f} seconds\")\n",
    "\n",
    "# Create the main GUI window\n",
    "root = tk.Tk()\n",
    "root.title(\"Letter Prediction GUI\")\n",
    "\n",
    "# Entry for user input\n",
    "entry_label = Label(root, text=\"Enter values for the 16 features separated by commas:\")\n",
    "entry_label.pack(pady=10)\n",
    "\n",
    "entry = Entry(root, width=50)\n",
    "entry.pack(pady=10)\n",
    "\n",
    "# Prediction button\n",
    "predict_button = Button(root, text=\"Predict Letter\", command=predict_letter)\n",
    "predict_button.pack(pady=10)\n",
    "\n",
    "# Result label\n",
    "result_var = StringVar()\n",
    "result_label = Label(root, textvariable=result_var)\n",
    "result_label.pack(pady=10)\n",
    "\n",
    "# Run the GUI\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847faa43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2c18c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Load the dataset\n",
    "data_path = 'letter-recognition.data'\n",
    "columns = ['letter'] + [f'feature_{i}' for i in range(16)]\n",
    "df = pd.read_csv(data_path, names=columns)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['target'] = label_encoder.fit_transform(df['letter'])\n",
    "X = df.drop(['letter', 'target'], axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Build the deep neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(16,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(26, activation='softmax'))  # 26 classes for letters\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "start_training_time = time.time()\n",
    "model.fit(X, y, epochs=30, batch_size=32)\n",
    "end_training_time = time.time()\n",
    "training_time = end_training_time - start_training_time\n",
    "print(f\"Training time: {training_time:.2f} seconds\")\n",
    "\n",
    "# Define the class mapping dictionary as a global variable\n",
    "class_mapping = {\n",
    "    0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'J',\n",
    "    10: 'K', 11: 'L', 12: 'M', 13: 'N', 14: 'O', 15: 'P', 16: 'Q', 17: 'R', 18: 'S', 19: 'T',\n",
    "    20: 'U', 21: 'V', 22: 'W', 23: 'X', 24: 'Y', 25: 'Z'\n",
    "}\n",
    "\n",
    "# Make predictions\n",
    "user_input = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]  # Replace with your own input\n",
    "new_data = np.array(user_input).reshape(1, -1)\n",
    "\n",
    "predictions = model.predict(new_data)\n",
    "predicted_class = np.argmax(predictions)\n",
    "predicted_letter = class_mapping[predicted_class]\n",
    "\n",
    "print(f\"The predicted class is: {predicted_class}, which corresponds to the letter: {predicted_letter}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8bd40d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768070e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Load the dataset\n",
    "data_path = 'letter-recognition.data'\n",
    "columns = ['letter'] + [f'feature_{i}' for i in range(16)]\n",
    "df = pd.read_csv(data_path, names=columns)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['target'] = label_encoder.fit_transform(df['letter'])\n",
    "X = df.drop(['letter', 'target'], axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Build the deep neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(16,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(26, activation='softmax'))  # 26 classes for letters\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "start_training_time = time.time()\n",
    "model.fit(X, y, epochs=30, batch_size=32)\n",
    "end_training_time = time.time()\n",
    "training_time = end_training_time - start_training_time\n",
    "print(f\"Training time: {training_time:.2f} seconds\")\n",
    "\n",
    "# Define the class mapping dictionary as a global variable\n",
    "class_mapping = {\n",
    "    0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'J',\n",
    "    10: 'K', 11: 'L', 12: 'M', 13: 'N', 14: 'O', 15: 'P', 16: 'Q', 17: 'R', 18: 'S', 19: 'T',\n",
    "    20: 'U', 21: 'V', 22: 'W', 23: 'X', 24: 'Y', 25: 'Z'\n",
    "}\n",
    "\n",
    "# Function to predict letter from user input\n",
    "def predict_letter_from_input():\n",
    "    user_input = input(\"Enter the values for the 16 features separated by commas: \")\n",
    "    user_input_list = [int(x) for x in user_input.split(',')]\n",
    "    \n",
    "    new_data = np.array(user_input_list).reshape(1, -1)\n",
    "    predictions = model.predict(new_data)\n",
    "    predicted_class = np.argmax(predictions)\n",
    "    predicted_letter = class_mapping[predicted_class]\n",
    "    return predicted_letter\n",
    "\n",
    "# Predict letter from user input\n",
    "predicted_letter = predict_letter_from_input()\n",
    "print(f\"The predicted letter is: {predicted_letter}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d54a44c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1ecb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Load the dataset\n",
    "data_path = 'letter-recognition.data'\n",
    "columns = ['letter'] + [f'feature_{i}' for i in range(16)]\n",
    "df = pd.read_csv(data_path, names=columns)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['target'] = label_encoder.fit_transform(df['letter'])\n",
    "X = df.drop(['letter', 'target'], axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Build the deep neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(16,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(26, activation='softmax'))  # 26 classes for letters\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "start_training_time = time.time()\n",
    "model.fit(X, y, epochs=30, batch_size=32)\n",
    "end_training_time = time.time()\n",
    "training_time = end_training_time - start_training_time\n",
    "print(f\"Training time: {training_time:.2f} seconds\")\n",
    "\n",
    "# Calculate training accuracy\n",
    "_, training_accuracy = model.evaluate(X, y)\n",
    "print(f\"Training Accuracy: {training_accuracy:.2f}\")\n",
    "\n",
    "# Define the class mapping dictionary as a global variable\n",
    "class_mapping = {\n",
    "    0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'J',\n",
    "    10: 'K', 11: 'L', 12: 'M', 13: 'N', 14: 'O', 15: 'P', 16: 'Q', 17: 'R', 18: 'S', 19: 'T',\n",
    "    20: 'U', 21: 'V', 22: 'W', 23: 'X', 24: 'Y', 25: 'Z'\n",
    "}\n",
    "\n",
    "# Function to predict letter from user input\n",
    "def predict_letter_from_input():\n",
    "    start_prediction_time = time.time()\n",
    "    user_input = input(\"Enter the values for the 16 features separated by commas: \")\n",
    "    user_input_list = [int(x) for x in user_input.split(',')]\n",
    "    \n",
    "    new_data = np.array(user_input_list).reshape(1, -1)\n",
    "    predictions = model.predict(new_data)\n",
    "    end_prediction_time = time.time()\n",
    "    prediction_time = end_prediction_time - start_prediction_time\n",
    "    \n",
    "    predicted_class = np.argmax(predictions)\n",
    "    predicted_letter = class_mapping[predicted_class]\n",
    "    return predicted_letter, prediction_time\n",
    "\n",
    "# Predict letter from user input\n",
    "predicted_letter, prediction_time = predict_letter_from_input()\n",
    "print(f\"The predicted letter is: {predicted_letter}\")\n",
    "print(f\"Prediction Time: {prediction_time:.2f} seconds\")\n",
    "print(f\"Training Time: {training_time:.2f} seconds\")\n",
    "print(f\"Training Accuracy: {training_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95960a67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff539c8-012d-40fa-bb47-016d84ca7e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
