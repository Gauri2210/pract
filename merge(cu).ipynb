{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dj3fRN8IKTOZ",
        "outputId": "2b0d75af-c915-41a7-ca23-332f46243cdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/afnan47/cuda.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8ZBLMjOKgeH",
        "outputId": "7c875dd1-42e9-4eee-ac23-88d930d4da37"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/afnan47/cuda.git\n",
            "  Cloning https://github.com/afnan47/cuda.git to /tmp/pip-req-build-omxvgdmm\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/afnan47/cuda.git /tmp/pip-req-build-omxvgdmm\n",
            "  Resolved https://github.com/afnan47/cuda.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4289 sha256=29677a02b3e7f3291d6a6c5d98c715ccffaf7fef826f69105bff9805e467eacf\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-p72ymd_z/wheels/aa/f3/44/e10c1d226ec561d971fcd4b0463f6bff08602afa928a3e7bc7\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "522JThRZK3wo",
        "outputId": "dc74d78c-f126-4f2d-f46a-3f567b75202a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile merge_sort.cu\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <chrono>\n",
        "#include <algorithm> // for min function\n",
        "using namespace std;\n",
        "// Kernel to merge two sorted halves\n",
        "__global__ void kernel_merge(int* arr, int* temp, int* subarray_sizes, int array_size) {\n",
        "  int idx = blockIdx.x * blockDim.x + threadIdx.x;//calculating global thread id\n",
        "  int left_start = idx * 2 * (*subarray_sizes);\n",
        "  if (left_start < array_size) {\n",
        "    int mid = min(left_start + (*subarray_sizes) - 1, array_size - 1);\n",
        "    int right_end = min(left_start + 2 * (*subarray_sizes) - 1, array_size - 1);\n",
        "    int i = left_start;\n",
        "    int j = mid + 1;\n",
        "    int k = left_start;\n",
        "    // Merge process\n",
        "    while (i <= mid && j <= right_end) {\n",
        "      if (arr[i] <= arr[j]) {\n",
        "        temp[k] = arr[i];\n",
        "        i++;\n",
        "      } else {\n",
        "        temp[k] = arr[j];\n",
        "        j++;\n",
        "      }\n",
        "      k++;\n",
        "    }\n",
        "    while (i <= mid) {\n",
        "      temp[k] = arr[i];\n",
        "      i++;\n",
        "      k++;\n",
        "    }\n",
        "    while (j <= right_end) {\n",
        "      temp[k] = arr[j];\n",
        "      j++;\n",
        "      k++;\n",
        "    }\n",
        "    // Copy the sorted subarray back to the original array\n",
        "    for (int t = left_start; t <= right_end; t++) {\n",
        "      arr[t] = temp[t];\n",
        "    }\n",
        "  }\n",
        "}\n",
        "void merge_sort(vector<int>& arr) {\n",
        "  int array_size = arr.size();\n",
        "  int* d_arr;\n",
        "  int* d_temp;\n",
        "  int* d_subarray_size;\n",
        "  // Allocate memory on the GPU\n",
        "  cudaMalloc(&d_arr, array_size * sizeof(int));\n",
        "  cudaMalloc(&d_temp, array_size * sizeof(int));\n",
        "  cudaMalloc(&d_subarray_size, sizeof(int)); // Holds the subarray size for each step\n",
        "  cudaMemcpy(d_arr, arr.data(), array_size * sizeof(int), cudaMemcpyHostToDevice);\n",
        "  int blockSize = 256; // Threads per block\n",
        "  int gridSize; // Number of blocks in the grid, depending on the subarray size\n",
        "  // Start with width of 1, then double each iteration\n",
        "  int width = 1;\n",
        "  while (width < array_size) {\n",
        "    cudaMemcpy(d_subarray_size, &width, sizeof(int), cudaMemcpyHostToDevice);\n",
        "    gridSize = (array_size / (2 * width)) + 1;\n",
        "    kernel_merge<<<gridSize, blockSize>>>(d_arr, d_temp, d_subarray_size, array_size);\n",
        "    cudaDeviceSynchronize(); // Ensure all threads finish before the next step\n",
        "    // Double the subarray width for the next iteration\n",
        "    width *= 2;\n",
        "  }\n",
        "  // Copy the sorted array back to the host\n",
        "  cudaMemcpy(arr.data(), d_arr, array_size * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "  // Free GPU memory\n",
        "  cudaFree(d_arr);\n",
        "  cudaFree(d_temp);\n",
        "  cudaFree(d_subarray_size);\n",
        "}\n",
        "int main() {\n",
        "  vector<int> arr = {6, 5, 4, 1, 7, 9, 8, 3, 2};\n",
        "  double start, end;\n",
        "  start =\n",
        "chrono::duration_cast<chrono::milliseconds>(chrono::system_clock::now().time_since_epoch()).count();\n",
        "  merge_sort(arr);\n",
        "  end =\n",
        "chrono::duration_cast<chrono::milliseconds>(chrono::system_clock::now().time_since_epoch()).count();\n",
        "  cout << \"Parallel merge sort time: \" << end - start << \" milliseconds\" << endl;\n",
        "  cout << \"Sorted array: \";\n",
        "  for (int num : arr) {\n",
        "    cout << num << \" \";\n",
        "  }\n",
        "  cout << endl;\n",
        "  return 0;\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58Yne8zsPhON",
        "outputId": "01bbaa9e-e0f1-40d3-bf55-f313bd4a5d36"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing merge_sort.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc merge_sort.cu -o merge\n",
        "!./merge\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJHbtj6JSi6y",
        "outputId": "402c3178-8564-47d7-ed10-2c0f3be05a43"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parallel merge sort time: 1 milliseconds\n",
            "Sorted array: 6 5 4 1 7 9 8 3 2 \n"
          ]
        }
      ]
    }
  ]
}